---
title: "Help_Frontiers_Ecosystem_APT"
author: "Colas Guillon"
date: "2025-01-28"
output: html_document
---
# Set Up
### This loads the packages
```{r, Library import}
rm(list = ls())
library(terra)#package to read rasters
library(sf) #package to read vectors in a data frame format
library(ggplot2)
library(dplyr)
library(xts)
library(tidyr)
library(purrr)
library(readr)
library(lubridate)
library(mgcv)
library(zoo)
library(broom)
```

### Import the data 
NDVI = 230 layers
CHIRPS = 720
```{r, Open study area}
# Rasters
lulc_mcc <-rast("./rasters/LULC_MCC.tif") # Values are NaN, 1, 3, 51, 53, 52, 7, 6, 10, 43, 42, 41, 2
lulc_kariba <- rast("./Rasters/detailled_LULC_Kariba_area.tif") # Values are 4, 2, 5, 7, 3, 1, 10, 6, NaN
ndvi <- rast("./rasters/NDVI.tif")
chirps <- rast("./rasters/CHIRPS_pentad.tif")

# Load Vectors
study_area <- vect("./Shapefile/Zone_etude_Kariba_lake.shp")
mcc <- vect("./Shapefile/MCC.shp")
protected_areas <- vect("./Shapefile/protected_areas.shp")

# Reproject vectors
study_area<- project(study_area, ndvi)
mcc<-project(mcc, ndvi)
protected_areas<-project(protected_areas, ndvi)
'''
# Make a list of the csvs containing ET data
csv_list <- list(
  miombo_mcc_41 = read_csv("./CSVs/41ET_Table.csv", col_types = cols(.geo = col_skip())),
  miombo_mcc_42 = read_csv("./CSVs/42ET_Table.csv", col_types = cols(.geo = col_skip())),
  miombo_mcc_43 = read_csv("./CSVs/43ET_Table.csv", col_types = cols(.geo = col_skip())),
  mopane_mcc_51 = read_csv("./CSVs/51ET_Table.csv", col_types = cols(.geo = col_skip())),
  mopane_mcc_52 = read_csv("./CSVs/52ET_Table.csv", col_types = cols(.geo = col_skip())),
  mopane_mcc_53 = read_csv("./CSVs/53ET_Table.csv", col_types = cols(.geo = col_skip())),
  riparian_mcc = read_csv("./CSVs/RipET_Table.csv", col_types = cols(.geo = col_skip())),
  crop_mcc = read_csv("./CSVs/CropET_Table.csv", col_types = cols(.geo = col_skip()))
)

# Rename ET columns with appropriate land cover names
csv_list <- map2(csv_list, names(csv_list), ~ rename(.x, !!.y := ET))

# Merge all CSVs using full_join by "system:index"
combined_df <- reduce(csv_list, full_join, by = "system:index")

# Rename "system:index" to "Date" and convert to Date format
combined_df <- combined_df %>%
  rename(Date = `system:index`) %>%
  mutate(Date = as.Date(Date))  # Ensure Date column is in correct format

# Print first few rows to check
head(combined_df)'''
```

# First Plots
```{r}'''
plot(ndvi)

# Plot
plot(lulc_mcc)
plot(study_area, add=T)

# Plot
plot(study_area)
plot(lulc_mcc)
plot(study_area, add = T)

# Convert raster grid to polygons
grid_polygons <- as.polygons(chirps)

# Plot the base raster first
plot(lulc_mcc, main="Raster with Transparent Grid Overlay")
plot(grid_polygons, add=TRUE, border="black", col=NA, lwd=0.5)

image(chirps, col=NA, add=TRUE)  # This prevents actual cell coloring
drawGrid(chirps, col="black", lwd=0.5)'''
```

# Define function to automate data processing
```{r}
# Define function 
process_raster <- function(raster, ref_raster, study_area){
  if ((res(raster)[1]) > (res(ref_raster)[1])){
    raster_aligned <- resample(raster, ref_raster, method="bilinear")
  }else {
    raster_aligned <- project(raster, ref_raster, method = "near")
  }
  raster_masked <- raster_aligned %>%
  crop(study_area) %>%
  mask(study_area) 
  return(raster_masked)
}
```

# Apply the function to project, clip and mask all the data
```{r}
chirps_masked <- process_raster(chirps, ndvi, study_area)
lulc_kariba_masked <- process_raster(lulc_kariba, ndvi, study_area)
lulc_mcc_masked <- process_raster(lulc_mcc, ndvi, study_area)
ndvi_masked <- process_raster(ndvi, ndvi, study_area)
```

### Isolate each of the landcover classes from Kariba
```{r}
# Extract the indices of the cells which are of each land-cover type
miombo_kariba <- which(lulc_kariba_masked[]==4) #we select the type of forests
mopane_kariba <- which(lulc_kariba_masked[]==5)
riparian_kariba <- which(lulc_kariba_masked[]==7)
crop_kariba <- which(lulc_kariba_masked[]==2)
all_kariba <- which(!is.na(values(lulc_mcc_masked)))

list_kariba <- list(miombo_kariba = miombo_kariba, 
                    mopane_kariba = mopane_kariba, 
                    riparian_kariba=riparian_kariba, 
                    crop_kariba=crop_kariba,
                    all_kariba = all_kariba)
```

### Isolate each of the landcover classes from the MCC 
```{r}
# Extract the indices of the cells which are of each landcover type
# Unique values are: 1, 3, 51, 53, 52, 7, 6, 10, 43, 42, 41, 2
miombo_mcc_all <- which(lulc_mcc_masked[]==41 | lulc_mcc_masked[]==42 | lulc_mcc_masked[]==43)
miombo_mcc_41<- which(lulc_mcc_masked[]==41)
miombo_mcc_42<- which(lulc_mcc_masked[]==42)
miombo_mcc_43<- which(lulc_mcc_masked[]==43) 
mopane_mcc_all <- which(lulc_mcc_masked[]==51 | lulc_mcc_masked[]==52 | lulc_mcc_masked[]==53)
mopane_mcc_51<- which(lulc_mcc_masked[]==51)
mopane_mcc_52 <- which(lulc_mcc_masked[]==52)
mopane_mcc_53 <- which(lulc_mcc_masked[]==53)
riparian_mcc <- which(lulc_mcc_masked[]==7)
crop_mcc <- which(lulc_mcc_masked[]==2)
all_mcc <- which(!is.na(values(lulc_mcc_masked)))

list_mcc <- list(
  miombo_mcc_all = miombo_mcc_all,
  miombo_mcc_41 = miombo_mcc_41, 
  miombo_mcc_42 = miombo_mcc_42, 
  miombo_mcc_43 = miombo_mcc_43, 
  mopane_mcc_all = mopane_mcc_all,
  mopane_mcc_51 = mopane_mcc_51, 
  mopane_mcc_52 = mopane_mcc_52, 
  mopane_mcc_53 = mopane_mcc_53, 
  riparian_mcc = riparian_mcc, 
  crop_mcc = crop_mcc,
  all_mcc = all_mcc
)
```

### Extract the dates from the NDVI
```{r, dates}
# This extracts the dates as a character string
ndvi.dates=names(ndvi_masked) #Extract the name of ndvi bands
# Because there the format is 2015_03_18_NDVI, we want to get rid of the NDVI
# Therefore we remove it using sub()
dates = sub("_NDVI", "", ndvi.dates) #we keep only the date
# Then we convert the character string into a date format object
ndvi_dates <- as.Date(dates,"%Y_%m_%d") #put in date format
```

### Extract Chirps Dates
```{r}
chirps_dates=names(chirps_masked) #Extract the name of ndvi bands
chirps_dates = sub("_precipitation", "", chirps_dates) #we keep only the date
chirps_dates <- as.Date(chirps_dates,"%Y%m%d")
```

# Define function to extract means
```{r}
extract_means <- function(list_indexes, raster, dates){
  
# First set up the output df
col_names <- names(list_indexes)   # Extract the names of the objects dynamically
output_df <- data.frame(matrix(ncol = length(col_names)+1, nrow = length(dates))) # Create an empty dataframe with these column names
colnames(output_df) <- c( "date", col_names) # Set the df to take the names from the list
output_df$date <- dates

# Now loop through the list and calculate the mean of each date for each land cover
  for (name in col_names){
    # Extract the means
    i <- list_indexes[[name]]
    df <- raster[i] # Extract the values of NDVI for the right cells using the index, store as dataframe with each date being a column
    col_mean <- colMeans(df, na.rm=T) #Take a mean of each column in the dataframe (i.e the date)
    output_df[[name]] <- col_mean # Add each vector of means to the columns in the df  
    rownames(output_df) <- NULL  # Remove row names
  }
return(output_df)
}
```

# Use the function to get the mean of each raster for each land cover
```{r}
# MCC 
ndvi_mcc_df <- extract_means(list_mcc, ndvi_masked, ndvi_dates)
ndvi_mcc_df

chirps_mcc_df <- extract_means(list_mcc, chirps_masked, chirps_dates)

#Kariba
ndvi_kariba_df <- extract_means(list_kariba, ndvi_masked, ndvi_dates)
chirps_kariba_df <- extract_means(list_kariba, chirps_masked, chirps_dates)
```

###  Plot NDVI vs Time - MCC
```{r}
# Convert rownames (dates) to a proper column
chirps_df_mcc_long <- chirps_mcc_df %>%
  mutate(Date = as.Date(chirps_mcc_df$date)) %>%
  pivot_longer(cols = -Date, names_to = "Land_Cover", values_to = "chirps_Mean")

# Plot using ggplot2
ggplot(chirps_df_mcc_long, aes(x = Date, y = chirps_Mean, color = Land_Cover)) +
  geom_line(linewidth = 0.5) +
  labs(title = "chirps Mean Over Time",
       x = "Date",
       y = "chirps Mean",
       color = "Land Cover Type") +
  theme_minimal()
```

#Process Timeseries to Remove Small Scale Variability
### Define functions to process the timeseries data into trends, rolling means and seasonality
```{r}
# Trend
extract_trend_xts <- function(xts_data) {
  trend_list <- list()
  
  for (col_name in colnames(xts_data)) {
    # Fit GAM model
    gam_fit <- gam(coredata(xts_data[, col_name]) ~ 
                   as.numeric(index(xts_data)) +  
                   s(yday(index(xts_data)), bs = "cc", k = 12))  
    
    # Predict full NDVI values
    full_ndvi <- predict(gam_fit, type = "response")
    
    # Predict seasonality term
    predictions <- predict(gam_fit, type = "terms")
    seasonality_values <- predictions[, 2]  # Extract seasonality
    
    # Trend = Full NDVI - Seasonality
    trend_values <- full_ndvi - seasonality_values
    
    # Convert trend predictions to xts
    trend_list[[col_name]] <- xts(trend_values, order.by = index(xts_data))
  }
  
  trend_xts <- do.call(merge, trend_list)
  return(trend_xts)
}

# Seasonality
extract_seasonality_xts <- function(xts_data) {
  
  seasonality_list <- list()
  
  for (col_name in colnames(xts_data)) {
    # Fit GAM model with seasonality
    gam_fit <- gam(coredata(xts_data[, col_name]) ~ 
                   as.numeric(index(xts_data)) +  
                   s(yday(index(xts_data)), bs = "cc", k = 12))  
    
    # Predict full NDVI values
    full_ndvi <- predict(gam_fit, type = "response")
    
    # Predict seasonality component separately (relative effect)
    predictions <- predict(gam_fit, type = "terms")
    seasonality_values <- predictions[, 2]  # Extract seasonality term
    
    # Adjust seasonality to absolute NDVI scale
    mean_ndvi <- mean(full_ndvi, na.rm = TRUE)
    seasonality_values <- seasonality_values + mean_ndvi  # Shift values to match NDVI scale
    
    # Convert seasonality predictions to xts
    seasonality_list[[col_name]] <- xts(seasonality_values, order.by = index(xts_data))
  }
  
  seasonality_xts <- do.call(merge, seasonality_list)
  
  # Get the first year and filter the seasonality for that year
  first_year <- year(min(index(seasonality_xts)))
  seasonality_xts_one_year <- seasonality_xts[year(index(seasonality_xts)) == first_year]
  
  return(seasonality_xts_one_year)
}

# Rolling Mean
extract_rolling_mean <- function(xts_data, window_size = 5) {
  
  # Apply a rolling mean (default: 5-day window)
  rolling_mean_xts <- rollapply(xts_data, width = window_size, FUN = mean, align = "center", fill = NA)
  
  return(rolling_mean_xts)
}

# Test trend Significance
test_trend_significance <- function(trend_xts) {
  
  results <- data.frame(LandCover = character(), Slope = numeric(), P_Value = numeric(), R_Squared = numeric(), stringsAsFactors = FALSE)
  
  for (col_name in colnames(trend_xts)) {
    # Prepare the data
    time_numeric <- as.numeric(index(trend_xts))  # Convert time to numeric for regression
    trend_values <- coredata(trend_xts[, col_name])  # Extract trend values
    
    # Fit linear regression: NDVI Trend ~ Time
    lm_model <- lm(trend_values ~ time_numeric)
    lm_summary <- summary(lm_model)  # Get model summary
    
    # Extract slope (beta coefficient), p-value, and R-squared
    slope <- coef(lm_model)[2]
    p_value <- coef(lm_summary)$coefficients[2, 4]  # Extract p-value of the slope
    r_squared <- lm_summary$r.squared  # Model fit quality
    
    # Store results
    results <- rbind(results, data.frame(LandCover = col_name, Slope = slope, P_Value = p_value, R_Squared = r_squared))
  }
  
  return(results)
}
```


# Compute each for NDVI
```{r}
ndvi_seasonality <- extract_seasonality_xts(xts_ndvi_mcc)
ndvi_trend <- extract_trend_xts(xts_ndvi_mcc)
ndvi_rolling_mean <- extract_rolling_mean_xts(xts_ndvi_mcc)

head(ndvi_trend)

plot(ndvi_seasonality)
plot(ndvi_trend)
plot(ndvi_rolling_mean)
```

```{r}


# Fit GAM model with a cyclic spline for seasonality
gam_fit <- gam(coredata(xts_ndvi_mcc[, "miombo_mcc_41"]) ~ 
               s(as.numeric(index(xts_ndvi_mcc)), bs = "cs") +  # Trend component
               s(yday(index(xts_ndvi_mcc)), bs = "cc", k = 12))  # Seasonal component

# Predict fitted values from the GAM model
predictions <- predict(gam_fit, type = "terms")  # Extract trend & seasonality separately

# Convert to xts objects
trend_xts <- xts(predictions[, 1], order.by = index(xts_ndvi_mcc))  # First term (trend)
seasonality_xts <- xts(predictions[, 2], order.by = index(xts_ndvi_mcc))  # Second term (seasonality)


# Convert xts objects to data frames for plotting
trend_df <- data.frame(Date = index(trend_xts), Trend = coredata(trend_xts))
seasonality_df <- data.frame(Date = index(seasonality_xts), Seasonality = coredata(seasonality_xts))
original_df <- data.frame(Date = index(xts_ndvi_mcc), NDVI = coredata(xts_ndvi_mcc[, "miombo_mcc_41"]))
```

# Plot the seasonality and trends
```{r}
# Merge all into one dataframe
plot_df <- original_df %>%
  left_join(trend_df, by = "Date") %>%
  left_join(seasonality_df, by = "Date")

# Plot NDVI with trend
ggplot(plot_df, aes(x = Date)) +
  geom_line(aes(y = Trend), color = "red", size = 1) +  # Trend
  geom_line(aes(y = Seasonality), color = "blue", size = 1) +  # Seasonality
  labs(title = "NDVI Trend from GAM",
       x = "Date", y = "NDVI",
       caption = "Gray = Original, Red = Trend") +
  theme_minimal()

ggplot(plot_df, aes(x = Date)) +
  geom_line(aes(y = Seasonality), color = "blue", size = 1) +  # Seasonality
  labs(title = "Extracted Seasonality from GAM",
       x = "Date", y = "Seasonal Component") +
  theme_minimal()
```


## CHIRPS
```{r}
rain_xts <- xts(miombo.rain.mean, order.by=rain.dates)
# Plot original data

# Apply a 30-day rolling mean to smooth short-term noise
rain_smoothed <- rollapply(rain_xts, width=15, FUN=mean, align="center", fill=NA)

# Plot smoothed time series
plot(rain_xts, main="rain Smoothed (5-frame Rolling Mean)", col="gray")
lines(rain_smoothed, col="red", lwd=2)  # Overlay smoothed series
```




